#system info
DEVICE = 'cpu'
# DEVICE = 'cuda:0'
EXPERT_DIR = './batch_second_layer'
EXPERT_CHUNKS_NUM = 400
EXPERT_CHUNK_LENGTH = 512
BAD_TOKENS = []

#for bert encoder
PRETRAINED_WEIGHTS = 'bert-base-uncased'

EMB_SIZE = 64

#for environment
STATE_SIZE = 20
CODE_SIZE = 2
PAD_TOKEN_IDX = 0
CLS_TOKEN_IDX = 1
SEP_TOKEN_IDX = 0
GEN_MAX_LEN = 20
TRAIN_REPORT_PERIOD = 50
MODEL_SAVE_PERIOD = 10000
ENCODING_FLAG = 'LAST2'

#batch size
BATCH_SIZE = 128

#for discriminator
ENCODED_ACTION_SIZE = 256
DISC_HIDDEN_UNIT_NUM = 128
DISC_LATENT_SIZE = 16
DISC_LR = 1e-4
CODEQ_LR = 1e-4
WEIGHT_FOR_CODE = 1
WEIGHT_FOR_KL = 1e-1
KL_STEP = 1e-3
IC = 0.5
WAIL_EPSILON = 1e-2
LIPSCHITZ = 1
DISC_STEP = 5
DISC_UPDATE_CNT = 1
AFTER_TRAIN_DISC_UPDATE_CNT = 1

#for actor_critic
ACTOR_UPDATE_CNT = 1
AC_HIDDEN_UNIT_NUM = 128
AC_HIDDEN_UNIT_STRIDE = 500
AC_HIDDEN_LAYER_NUM = 1
AC_LAST2_UNIT_NUM = 128
AC_LR = 1e-4
PRETRAIN_LR = 3e-4
CRITIC_HIDDEN_UNIT_NUM = 32
TOP_K = 40
EPSILON = 0.15
ENTROPY = 1e-2
ACTOR_COEF = 1
CRITIC_COEF = 1
PRETRAIN_COEF = 0
INFO_COEF = 1
PPO_STEP = 5
PRETRAIN_SAVEPATH = './model_save/pretrain.pt'
MODEL_SAVEPATH = './model_save/trained'

#for memory
GAMMA = 0.99
LAMBDA = 0.95
THRESHOLD_LEN = 2048
HORIZON_THRESHOLD = 20

#for statistics
MOVING_AVERAGE = 50

#for action_autoencoder
VOCAB_SIZE = 3600
AUTOENCODER_HIDDEN_UNIT_NUM = 300
COMPRESSED_VOCAB_SIZE = 54
AUTOENCODER_BATCH_SIZE = 128
AUTOENCODER_KL_COEF = 0.1
AUTOENCODER_SAVE_PATH = './model_save/encoder'

#for action_encoder
ACTIONENCODER_BATCH_SIZE = 128
ACTIONENCODER_SAVE_PATH = './model_save/actionencoder.pt'

#tmp
REWARD_LIST = []