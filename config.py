#system info
DEVICE = 'cuda:0'
EXPERT_DIR = './expert_data_last'
EXPERT_CHUNKS_NUM = 400
EXPERT_CHUNK_LENGTH = 512
BAD_TOKENS = [102, 1029, 999, 1012, 1008, 2184]
#<SEP> ? ! . * 10

#for bert encoder
PRETRAINED_WEIGHTS = 'bert-base-uncased'

#for environment
STATE_SIZE = 768
CODE_SIZE = 2
CLS_TOKEN_IDX = 101
SEP_TOKEN_IDX = 102
GEN_MAX_LEN = 20
TRAIN_REPORT_PERIOD = 10

#batch size
BATCH_SIZE = 64

#for discriminator
DISC_HIDDEN_UNIT_NUM = 250
DISC_HIDDEN_LAYER_NUM = 2
DISC_LR = 1e-4
WEIGHT_FOR_CODE = 0.5
DISC_STEP = 2

#for actor_critic
AC_HIDDEN_UNIT_NUM = 2000
AC_HIDDEN_UNIT_STRIDE = 1000
AC_HIDDEN_LAYER_NUM = 2
AC_LR = 1e-5
PRETRAIN_LR = 5e-5
CRITIC_HIDDEN_UNIT_NUM = 500
TOP_K = 40
EPSILON = 0.15
ENTROPY = 3e-2
ACTOR_COEF = 1
CRITIC_COEF = 1
PPO_STEP = 5
PRETRAIN_SAVEPATH = './model_save/pretrain.pt'

#for memory
GAMMA = 0.98
LAMBDA = 0.95
THRESHOLD_LEN = 512
HORIZON_THRESHOLD = 5

#for statistics
MOVING_AVERAGE = 50

#for action_autoencoder
#not used
VOCAB_SIZE = 30522
COMPRESSED_VOCAB_SIZE = 768
AUTOENCODER_BATCH_SIZE = 128
AUTOENCODER_SAVE_PATH = './model_save/encoder.pt'