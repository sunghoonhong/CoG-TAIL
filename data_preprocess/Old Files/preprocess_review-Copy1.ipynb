{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ozj8ZdU3xC4F"
   },
   "outputs": [],
   "source": [
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "\n",
    "!pip install pytorch_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z5ELz6xPxBgf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import torch\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from pytorch_transformers import BertTokenizer, BertModel\n",
    "\n",
    "import re\n",
    "\n",
    "df = pd.read_csv('/content/gdrive/My Drive/IMDB_Dataset.csv', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mqzReP2yxBgj"
   },
   "outputs": [],
   "source": [
    "# Sentiment 1, 0으로 바꾸기\n",
    "df['sentiment'] = (df['sentiment'] == 'positive').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kEgV8AqnxBgl"
   },
   "outputs": [],
   "source": [
    "# 문장 단위로 쪼개기\n",
    "df['review'] = df.review.map(sent_tokenize)\n",
    "raw_reviews = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fu-0Mgq4FKRF"
   },
   "outputs": [],
   "source": [
    "# 클렌징\n",
    "stop = stopwords.words('english')\n",
    "lmtzr = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "def clean_review(text: str) -> str:\n",
    "    # 1. unicode to ASCII\n",
    "    text = unicodeToAscii(text)\n",
    "            \n",
    "    # 2. Remove HTML\n",
    "    text = BeautifulSoup(text, \"lxml\").get_text()\n",
    "    \n",
    "    # 4. Tokenize\n",
    "    text = [word for word in nltk.word_tokenize(text)]\n",
    "    \n",
    "    # 5. Remove Stop Words\n",
    "    \n",
    "    text = [word for word in text if word not in stop and len(word) >= 3]\n",
    "    \n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = []\n",
    "  \n",
    "for review in raw_reviews:\n",
    "    text = review[0]\n",
    "    code = review[1]\n",
    "    for s in text:\n",
    "        new_s = clean_review(s)\n",
    "        if(len(new_s) > 10 and new_s[0].isalpha()):\n",
    "            reviews.append((new_s, code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9N7Dv9PrXUrY"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "\n",
    "with gzip.open('/content/gdrive/My Drive/pre_reviews.pickle', 'wb') as f:\n",
    "    pickle.dump(reviews, f)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "preprocess_review",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
